{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVz8lLM/aiNtaKR1sspsSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnilayy/Yolact/blob/main/Yolact.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CLONING THE YOLACT REPO"
      ],
      "metadata": {
        "id": "TVf_ajfjTuhG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXrGBciORtr7"
      },
      "outputs": [],
      "source": [
        "# Make sure we're in the top folder\n",
        "# %cd /content\n",
        "\n",
        "# Clone the repo\n",
        "!git clone https://github.com/dbolya/yolact.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DCNv2\n",
        "DCNv2 is needed for making Yolact work"
      ],
      "metadata": {
        "id": "SJV-oRbXUaaS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7XrENaqJU1C"
      },
      "source": [
        "# Change to the right directory\n",
        "%cd /content/yolact/external/DCNv2\n",
        "\n",
        "# Build DCNv2\n",
        "!python setup.py build develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PRETRAINED WEIGHTS\n",
        "Getting pretrained weights from a repo\n"
      ],
      "metadata": {
        "id": "QUl0Njt6U39D"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "683HeW9lJ6cA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4e6888-8da5-4c7c-865b-7b3c5b9bc743"
      },
      "source": [
        "# Make sure we're in the top folder\n",
        "# %cd /content\n",
        "\n",
        "# Clone the repo\n",
        "# !git clone https://github.com/chentinghao/download_google_drive.git\n",
        "\n",
        "# Create a new directory for the pre-trained weights\n",
        "# !mkdir -p /content/yolact/weights\n",
        "\n",
        "# Download the file\n",
        "!python ./download_google_drive/download_gdrive.py 1ZPu1YR2UzGHQD0o1rEqy-j5bmEm3lbyP ./yolact/weights/yolact_plus_resnet50_54_800000.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./download_google_drive/download_gdrive.py:50: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if len(sys.argv) is not 3:\n",
            "32.0kB [00:00, 104MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)                "
      ],
      "metadata": {
        "id": "qwtpPDZe9IPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '1yp7ZbbDwvMiFJEq4ptVKTYTI2VeRDXl0'\n",
        "destination = './yolact/weights/yolact_resnet50_54_800000.pth'\n",
        "download_file_from_google_drive(file_id, destination) \n"
      ],
      "metadata": {
        "id": "UK-u25YIFzX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CUSTOM DATASET\n",
        "* Drop the file with your custom dataset in the /content by dragging and dropping as a zip folder.\n",
        "*Unzip the zip folder as follows:\n",
        "```\n",
        "!unzip -q ../*custom_dataset*.zip -d ../\n",
        "```\n",
        "*Click on the following config file link: /content/yolact/data/config.py.\n",
        "*Under this file, go to \"DATASETS\" and add the following. \n",
        "```\n",
        "my_custom_dataset = dataset_base.copy({\n",
        "    'name': 'My Dataset',\n",
        "\n",
        "    'train_images': 'path_to_training_images',\n",
        "    'train_info':   'path_to_training_annotation',\n",
        "\n",
        "    'valid_images': 'path_to_validation_images',\n",
        "    'valid_info':   'path_to_validation_annotation',\n",
        "\n",
        "    'has_gt': True,\n",
        "    'class_names': ('my_class_id_1', 'my_class_id_2', 'my_class_id_3', ...)\n",
        "})\n",
        "```\n",
        "*In the above, add the path to your train and test dataset and annotations files, from the custom dataset you unziped. \n",
        "\n"
      ],
      "metadata": {
        "id": "VZNyCaB8dYnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "cWzdG3XFYnGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolact/train.py --config= yolact_base_config"
      ],
      "metadata": {
        "id": "__PAgTs9c2i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains using the base config with a batch size of 8 (the default).\n",
        "# !python /content/yolact/train.py --config=yolact_base_config\n",
        "\n",
        "# Trains yolact_base_config with a batch_size of 5. For the 550px models, 1 batch takes up around 1.5 gigs of VRAM, so specify accordingly.\n",
        "# !python /content/yolact/train.py --config=yolact_base_config --batch_size=5\n",
        "\n",
        "# Resume training yolact_base with a specific weight file and start from the iteration specified in the weight file's name.\n",
        "# !python /content/yolact/train.py --config=yolact_base_config --resume=weights/yolact_base_10_32100.pth --start_iter=-1\n",
        "\n",
        "# Use the help option to see a description of all available command line arguments\n",
        "# !python /content/yolact/train.py --help"
      ],
      "metadata": {
        "id": "WXq-dE5ydv2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-train the image based model\n",
        "# !python train.py --config=yolact_edge_youtubevis_config\n",
        "\n",
        "# Train the flow (warping) module\n",
        "# !python train.py --config=yolact_edge_vid_trainflow_config --resume=./weights/yolact_edge_youtubevis_847_50000.pth\n",
        "\n",
        "# Fine tune the network jointly\n",
        "# !python train.py --config=yolact_edge_vid_config --resume=./weights/yolact_edge_vid_trainflow_144_100000.pth\n"
      ],
      "metadata": {
        "id": "NQYyWPpqVP-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TESTING THE MODEL"
      ],
      "metadata": {
        "id": "IMZYBJkeYWSa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mPeJJ4bNoQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd3d6c9-7aa8-4ed6-b750-d0a4e8858c67"
      },
      "source": [
        "!python /content/yolact/eval.py --trained_model=/content/yolact/weights/yolact_resnet50_54_800000.pth --config=yolact_base_config --score_threshold=0.15 --top_k=15 --display --image=/content/tennis.jpg\n",
        "\n",
        "# Display qualitative results on the specified image: --image=my_image.png \n",
        "# Process a whole folder of images: --images=path/to/input/folder:path/to/output/folder \n",
        "# Process an image and save it to another file: --image=input_image.png:output_image.png \n",
        "\n",
        "# Display a video in real-time. \"--video_multiframe\" will process that many frames at once for improved performance.\n",
        "# If you want, use \"--display_fps\" to draw the FPS directly on the frame.\n",
        "# --video_multiframe=4 --video=my_video.mp4 \n",
        "\n",
        "# Display a webcam feed in real-time. If you have multiple webcams pass the index of the webcam you want instead of 0.\n",
        "# --video_multiframe=4 --video=0 \n",
        "\n",
        "# Process a video and save it to another file. This uses the same pipeline as the ones above now, so it's fast!\n",
        "# --video_multiframe=4 --video=input_video.mp4:output_video.mp4 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:256: UserWarning: 'downsample_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n",
            "/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:256: UserWarning: 'lat_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n",
            "/usr/local/lib/python3.8/dist-packages/torch/jit/_recursive.py:256: UserWarning: 'pred_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\"'{}' was found in ScriptModule constants, \"\n",
            "Loading model...Traceback (most recent call last):\n",
            "  File \"/content/yolact/eval.py\", line 1098, in <module>\n",
            "    net.load_weights(args.trained_model)\n",
            "  File \"/content/yolact/yolact.py\", line 479, in load_weights\n",
            "    state_dict = torch.load(path)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 795, in load\n",
            "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 1002, in _legacy_load\n",
            "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
            "_pickle.UnpicklingError: invalid load key, '<'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DISPLAYING THE RESULTS \n"
      ],
      "metadata": {
        "id": "h6Ea653dX97b"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U2u5-LKOHeV"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "output_images = Path('output_images')\n",
        "\n",
        "def show_image(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plt.figure(figsize=(16,16))\n",
        "  plt.imshow(img_cvt)\n",
        "  plt.show()\n",
        "\n",
        "# Iterate through all of the output images and display them\n",
        "for img_path in output_images.iterdir():\n",
        "  print(img_path)\n",
        "  show_image(str(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive\n",
        "!mkdir /content/yolact/new_weigths\n",
        "!cp /content/drive/MyDrive/yolact_plus_resnet50_54_800000.pth /content/yolact/new_weigths/yolact_plus_resnet50_54_800000\n"
      ],
      "metadata": {
        "id": "h14q4cU3Q0gK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}